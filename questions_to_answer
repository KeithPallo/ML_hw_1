(0.5 points) Which other student, if any, is in your group? (either names or netIDs is fine)


(0.5 points) Did you alter the Node data structure? If so, how and why? (2 sentences)



(1 point) How did you handle missing attributes, and why did you choose this strategy? (2 sentences)
 - Split on them (i.e. do not remove them)

(1 point) How did you perform pruning, and why did you choose this strategy? (4 sentences)
- Prune if information gain is decreased

(2 points) Now you will try your learner on the house_votes_84.data, and plot learning curves. Specifically,
you should experiment under two settings: with pruning, and without pruning. Use training set sizes ranging
between 10 and 300 examples. For each training size you choose, perform 100 random runs, for each run testing
on all examples not used for training (see testPruningOnHouseData from unit_tests.py for one example of this).

- Potentailly perform 3 different runs: 10, 100, 300

Plot the average accuracy of the 100 runs as one point on a learning curve (x-axis = number of training examples,
y-axis = accuracy on test data). Connect the points to show one line representing accuracy with pruning, the other
 without. Include your plot in your pdf, and answer two questions:

In about a sentence, what is the general trend of both lines as training set size increases, and why does this make sense?
In about two sentences, how does the advantage of pruning change as the data set size increases? Does this make sense, and why or why not?


Note: depending on your particular approach, pruning may not improve accuracy consistently or may
 decrease it (especially for small data set sizes). You can still receive full credit for this
 as long as your approach is reasonable and correctly implemented.
